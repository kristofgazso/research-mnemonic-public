"""!Take JSON shares generated by create_shares.py and reconstruct the original secret phrase.


Requisites 
----------
(To read about the format needed by the following files, read the documentation in create_shares.py)

1) At least t JSON shares, in the format generated by create_shares.py, must be present in the
folder /shares. Here, t represents the threshold used when creating the shares

2) Unless the JSON shares are verbose, the file reconstruction_data.json, containing the public 
reconstruction data, should also be present in the folder. This file is not needed if the shares are
verbose, in which case one can run this script with the -v flag.


Execution and inputs
--------------------
This script should be called from the command line. It has only one optional flag

-v, --verbose: If this flag is used, the public reconstruction data is taken directly from the JSON
shares. The script verifies the consistency of this data among all the shares, throwing an exception
if this data is not consistent.


Outputs
-------
The file secret_reconstructed.txt is generated in the script's folder. The reconstructed secret is
also printed on the command line.
"""
import hashlib

from modules import shamir, word_coding
import argparse
import glob
import json


def get_reconstruction_data(dict):
	"""!Gets the public reconstruction data from a JSON file, in the format needed by shamir.py"""

	return (
		dict['total_shares'],
		dict['threshold'],
		dict['primitive_poly'],
		dict['dictionary'].split(' ')
		)


# Parser initialized to check for --verbose flag.
parser = argparse.ArgumentParser()
parser.add_argument('-v', '--verbose', action='store_true', help='use if public reconstruction data is to be taken from the JSON shares')
args = parser.parse_args()
verbose = args.verbose


#Search JSON files with names of the form 'share_i.json', where 'i' is an integer.
list_of_share_filenames = glob.glob('shares/share*[0-9].json')


# Extract reconstruction data and Galois-field parameters.
# In the verbose case, it is picked from one of the shares.
reconstruction_json_path = list_of_share_filenames[0] if verbose else 'shares/reconstruction_data.json'
with open(reconstruction_json_path, 'r') as json_file:
	data = json.load(json_file)
try:
	total_shares, threshold, primitive_poly, word_list = get_reconstruction_data(data)
except KeyError:
	if verbose:
		raise RuntimeError('-v flag was added, but not all the shares are verbose')
	else:
		raise RuntimeError('shares/reconstruction_data.json does not contain all the reconstruction data')

dict_bits = word_coding.get_dictionary_bits(word_list)

polynomial_degree = shamir.get_polynomial_degree(primitive_poly)
num_checksum_bits = polynomial_degree // 32

num_words = (shamir.get_polynomial_degree(primitive_poly)+num_checksum_bits)//dict_bits


#Extract ID and mnenmonic share data from each share, in numerical form via word_coding
x_id = []
y_shares = []

for json_filename in list_of_share_filenames:
	with open(json_filename, 'r') as json_file:
		json_share = json.load(json_file)
	#Check the consistency of the reconstruction data (if verbose) and number of words.
	if verbose:
		try:
			assert get_reconstruction_data(json_share) == (total_shares, threshold, primitive_poly, word_list), 'Shares have incompatible reconstruction data.'
		except KeyError:
			raise RuntimeError('-v flag was added, but not all the shares are verbose')
	assert len(json_share['share']) == num_words, 'A share has a number of words inconsistent with the given polynomial and dictionary'

	binary_share = word_coding.encode_words(word_list, json_share['share'])
	x = int(binary_share[-num_checksum_bits:], 2)
	y = int(binary_share[:-num_checksum_bits], 2)
	x_id.append(x)
	y_shares.append(y)


# Call the reconstruction routine and save to file
assert threshold <= len(y_shares), 'Not enough shares for secret reconstruction'

# Our shares only encoded the entropy of the secret seed
reconstructed_secret_entropy = shamir.secret_reconstruction(x_id, y_shares, primitive_poly)

# We need to derive the checksum to decode a valid seed
entropyHashBytes = hashlib.sha256(reconstructed_secret_entropy.to_bytes(polynomial_degree//8, 'big')).hexdigest()
digest_binary = format(int(entropyHashBytes.zfill(64), 16), 'b').zfill(256)
checksum = digest_binary[:num_checksum_bits]

# Combine entropy and checksum
reconstructed_secret = int(format(reconstructed_secret_entropy, 'b').zfill(polynomial_degree) + checksum, 2)

seed_phrase = word_coding.decode_words(word_list, format(reconstructed_secret, 'b').zfill(dict_bits*num_words))
print(seed_phrase)
with open('secret_reconstructed.txt', 'w') as file:
	file.write(' '.join(seed_phrase))